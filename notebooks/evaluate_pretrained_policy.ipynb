{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Pretrained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on:\n",
    "https://github.com/huggingface/lerobot/blob/main/examples/2_evaluate_pretrained_policy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import gym_pusht  # noqa: F401\n",
    "import gymnasium as gym\n",
    "import imageio\n",
    "import numpy\n",
    "import torch\n",
    "from IPython.display import Video\n",
    "\n",
    "from lerobot.common.policies.diffusion.modeling_diffusion import DiffusionPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Device 'cuda' is not available. Switching to 'mps'.\n"
     ]
    }
   ],
   "source": [
    "# Create a directory to store the video of the evaluation\n",
    "output_directory = Path(\"outputs/eval/example_pusht_diffusion\")\n",
    "output_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Select your device\n",
    "device = \"mps\"\n",
    "\n",
    "# Provide the [hugging face repo id](https://huggingface.co/lerobot/diffusion_pusht):\n",
    "pretrained_policy_path = \"lerobot/diffusion_pusht\"\n",
    "# OR a path to a local outputs/train folder.\n",
    "# pretrained_policy_path = Path(\"outputs/train/example_pusht_diffusion\")\n",
    "\n",
    "policy = DiffusionPolicy.from_pretrained(pretrained_policy_path)\n",
    "\n",
    "# Initialize evaluation environment to render two observation types:\n",
    "# an image of the scene and state/position of the agent. The environment\n",
    "# also automatically stops running after 300 interactions/steps.\n",
    "env = gym.make(\n",
    "    \"gym_pusht/PushT-v0\",\n",
    "    obs_type=\"pixels_agent_pos\",\n",
    "    max_episode_steps=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'observation.image': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 96, 96)), 'observation.state': PolicyFeature(type=<FeatureType.STATE: 'STATE'>, shape=(2,))}\n",
      "Dict('agent_pos': Box(0.0, 512.0, (2,), float64), 'pixels': Box(0, 255, (96, 96, 3), uint8))\n"
     ]
    }
   ],
   "source": [
    "# We can verify that the shapes of the features expected by the policy match the ones from the observations\n",
    "# produced by the environment\n",
    "print(policy.config.input_features)  # channel first\n",
    "print(env.observation_space)  # channel last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': PolicyFeature(type=<FeatureType.ACTION: 'ACTION'>, shape=(2,))}\n",
      "Box(0.0, 512.0, (2,), float32)\n"
     ]
    }
   ],
   "source": [
    "# Similarly, we can check that the actions produced by the policy will match the actions expected by the\n",
    "# environment\n",
    "print(policy.config.output_features)\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the policy and environments to prepare for rollout\n",
    "policy.reset()\n",
    "numpy_observation, info = env.reset(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=0 reward=np.float64(0.0) terminated=False\n",
      "step=1 reward=np.float64(0.0) terminated=False\n",
      "step=2 reward=np.float64(0.0) terminated=False\n",
      "step=3 reward=np.float64(0.0) terminated=False\n",
      "step=4 reward=np.float64(0.0) terminated=False\n",
      "step=5 reward=np.float64(0.0) terminated=False\n",
      "step=6 reward=np.float64(0.0) terminated=False\n",
      "step=7 reward=np.float64(0.0) terminated=False\n",
      "step=8 reward=np.float64(0.0) terminated=False\n",
      "step=9 reward=np.float64(0.0) terminated=False\n",
      "step=10 reward=np.float64(0.0) terminated=False\n",
      "step=11 reward=np.float64(0.0) terminated=False\n",
      "step=12 reward=np.float64(0.0) terminated=False\n",
      "step=13 reward=np.float64(0.0) terminated=False\n",
      "step=14 reward=np.float64(0.0) terminated=False\n",
      "step=15 reward=np.float64(0.0) terminated=False\n",
      "step=16 reward=np.float64(0.0) terminated=False\n",
      "step=17 reward=np.float64(0.0) terminated=False\n",
      "step=18 reward=np.float64(0.0) terminated=False\n",
      "step=19 reward=np.float64(0.0) terminated=False\n",
      "step=20 reward=np.float64(0.0) terminated=False\n",
      "step=21 reward=np.float64(0.0) terminated=False\n",
      "step=22 reward=np.float64(0.0) terminated=False\n",
      "step=23 reward=np.float64(0.0) terminated=False\n",
      "step=24 reward=np.float64(0.0) terminated=False\n",
      "step=25 reward=np.float64(0.0) terminated=False\n",
      "step=26 reward=np.float64(0.0) terminated=False\n",
      "step=27 reward=np.float64(0.0) terminated=False\n",
      "step=28 reward=np.float64(0.0) terminated=False\n",
      "step=29 reward=np.float64(0.0) terminated=False\n",
      "step=30 reward=np.float64(0.0) terminated=False\n",
      "step=31 reward=np.float64(0.0) terminated=False\n",
      "step=32 reward=np.float64(0.0) terminated=False\n",
      "step=33 reward=np.float64(0.0) terminated=False\n",
      "step=34 reward=np.float64(0.004331024969213748) terminated=False\n",
      "step=35 reward=np.float64(0.026436238568168027) terminated=False\n",
      "step=36 reward=np.float64(0.048948479184788195) terminated=False\n",
      "step=37 reward=np.float64(0.07391806682128935) terminated=False\n",
      "step=38 reward=np.float64(0.09641014892501618) terminated=False\n",
      "step=39 reward=np.float64(0.10782653450412456) terminated=False\n",
      "step=40 reward=np.float64(0.11272767346334414) terminated=False\n",
      "step=41 reward=np.float64(0.11730298165716972) terminated=False\n",
      "step=42 reward=np.float64(0.12068450613443223) terminated=False\n",
      "step=43 reward=np.float64(0.12332072588491143) terminated=False\n",
      "step=44 reward=np.float64(0.12550178716516777) terminated=False\n",
      "step=45 reward=np.float64(0.12706584814907973) terminated=False\n",
      "step=46 reward=np.float64(0.12822544508133635) terminated=False\n",
      "step=47 reward=np.float64(0.12917254945391038) terminated=False\n",
      "step=48 reward=np.float64(0.12970218402467215) terminated=False\n",
      "step=49 reward=np.float64(0.1300282984553087) terminated=False\n",
      "step=50 reward=np.float64(0.13023653003679475) terminated=False\n",
      "step=51 reward=np.float64(0.13040402746973884) terminated=False\n",
      "step=52 reward=np.float64(0.13046514908503043) terminated=False\n",
      "step=53 reward=np.float64(0.13037331977718217) terminated=False\n",
      "step=54 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=55 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=56 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=57 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=58 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=59 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=60 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=61 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=62 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=63 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=64 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=65 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=66 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=67 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=68 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=69 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=70 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=71 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=72 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=73 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=74 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=75 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=76 reward=np.float64(0.13032519573964654) terminated=False\n",
      "step=77 reward=np.float64(0.1452522546777843) terminated=False\n",
      "step=78 reward=np.float64(0.18170335729457743) terminated=False\n",
      "step=79 reward=np.float64(0.21680854308251896) terminated=False\n",
      "step=80 reward=np.float64(0.24752204797428212) terminated=False\n",
      "step=81 reward=np.float64(0.2727432384639811) terminated=False\n",
      "step=82 reward=np.float64(0.2917697478560234) terminated=False\n",
      "step=83 reward=np.float64(0.3026782197872331) terminated=False\n",
      "step=84 reward=np.float64(0.32102177193353354) terminated=False\n",
      "step=85 reward=np.float64(0.36183221365798846) terminated=False\n",
      "step=86 reward=np.float64(0.39558381277897536) terminated=False\n",
      "step=87 reward=np.float64(0.43921169535396903) terminated=False\n",
      "step=88 reward=np.float64(0.5137473114136469) terminated=False\n",
      "step=89 reward=np.float64(0.6018419244165287) terminated=False\n",
      "step=90 reward=np.float64(0.682405372496536) terminated=False\n",
      "step=91 reward=np.float64(0.7315452558721762) terminated=False\n",
      "step=92 reward=np.float64(0.7503405197780658) terminated=False\n",
      "step=93 reward=np.float64(0.7430276602721889) terminated=False\n",
      "step=94 reward=np.float64(0.7246857672243993) terminated=False\n",
      "step=95 reward=np.float64(0.712024741810571) terminated=False\n",
      "step=96 reward=np.float64(0.7085196438086034) terminated=False\n",
      "step=97 reward=np.float64(0.7053691357123587) terminated=False\n",
      "step=98 reward=np.float64(0.6953864993891091) terminated=False\n",
      "step=99 reward=np.float64(0.6953864993891091) terminated=False\n",
      "step=100 reward=np.float64(0.6953864993891091) terminated=False\n",
      "step=101 reward=np.float64(0.6953864993891091) terminated=False\n",
      "step=102 reward=np.float64(0.6953864993891091) terminated=False\n",
      "step=103 reward=np.float64(0.6953864993891091) terminated=False\n",
      "step=104 reward=np.float64(0.6953864993891091) terminated=False\n",
      "step=105 reward=np.float64(0.6953864993891091) terminated=False\n",
      "step=106 reward=np.float64(0.6953864993891091) terminated=False\n",
      "step=107 reward=np.float64(0.6953864993891091) terminated=False\n",
      "step=108 reward=np.float64(0.6953864993891091) terminated=False\n",
      "step=109 reward=np.float64(0.6953864993891091) terminated=False\n",
      "step=110 reward=np.float64(0.6953864993891091) terminated=False\n",
      "step=111 reward=np.float64(0.6953864993891091) terminated=False\n",
      "step=112 reward=np.float64(0.6953864993891091) terminated=False\n",
      "step=113 reward=np.float64(0.7253263946985712) terminated=False\n",
      "step=114 reward=np.float64(0.7643790336128795) terminated=False\n",
      "step=115 reward=np.float64(0.7997639486029243) terminated=False\n",
      "step=116 reward=np.float64(0.834008936425074) terminated=False\n",
      "step=117 reward=np.float64(0.8692154981495008) terminated=False\n",
      "step=118 reward=np.float64(0.9043299769748061) terminated=False\n",
      "step=119 reward=np.float64(0.8903071831701105) terminated=False\n",
      "step=120 reward=np.float64(0.8868939291575869) terminated=False\n",
      "step=121 reward=np.float64(0.8868939291575869) terminated=False\n",
      "step=122 reward=np.float64(0.8868939291575869) terminated=False\n",
      "step=123 reward=np.float64(0.8868939291575869) terminated=False\n",
      "step=124 reward=np.float64(0.8868939291575869) terminated=False\n",
      "step=125 reward=np.float64(0.8868939291575869) terminated=False\n",
      "step=126 reward=np.float64(0.8868939291575869) terminated=False\n",
      "step=127 reward=np.float64(0.8868939291575869) terminated=False\n",
      "step=128 reward=np.float64(0.8868939291575869) terminated=False\n",
      "step=129 reward=np.float64(0.8868939291575869) terminated=False\n",
      "step=130 reward=np.float64(0.8868939291575869) terminated=False\n",
      "step=131 reward=np.float64(0.8868939291575869) terminated=False\n",
      "step=132 reward=np.float64(0.8868939291575869) terminated=False\n",
      "step=133 reward=np.float64(0.8868939291575869) terminated=False\n",
      "step=134 reward=np.float64(0.8868939291575869) terminated=False\n",
      "step=135 reward=np.float64(0.9727362669921931) terminated=False\n",
      "step=136 reward=np.float64(0.9811467938725599) terminated=False\n",
      "step=137 reward=np.float64(0.9159946950046522) terminated=False\n",
      "step=138 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=139 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=140 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=141 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=142 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=143 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=144 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=145 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=146 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=147 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=148 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=149 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=150 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=151 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=152 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=153 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=154 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=155 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=156 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=157 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=158 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=159 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=160 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=161 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=162 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=163 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=164 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=165 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=166 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=167 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=168 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=169 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=170 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=171 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=172 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=173 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=174 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=175 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=176 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=177 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=178 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=179 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=180 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=181 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=182 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=183 reward=np.float64(0.9117243432785848) terminated=False\n",
      "step=184 reward=np.float64(0.9426822905150436) terminated=False\n",
      "step=185 reward=np.float64(0.962961899979686) terminated=False\n",
      "step=186 reward=np.float64(0.971805541764849) terminated=False\n",
      "step=187 reward=np.float64(0.9771182969517339) terminated=False\n",
      "step=188 reward=np.float64(0.983021613280464) terminated=False\n",
      "step=189 reward=np.float64(0.9940676339168445) terminated=False\n",
      "step=190 reward=np.float64(1.0) terminated=True\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Prepare to collect every rewards and all the frames of the episode,\n",
    "# from initial state to final state.\n",
    "rewards = []\n",
    "frames = []\n",
    "\n",
    "# Render frame of the initial state\n",
    "frames.append(env.render())\n",
    "\n",
    "step = 0\n",
    "done = False\n",
    "while not done:\n",
    "    # Prepare observation for the policy running in Pytorch\n",
    "    state = torch.from_numpy(numpy_observation[\"agent_pos\"])\n",
    "    image = torch.from_numpy(numpy_observation[\"pixels\"])\n",
    "\n",
    "    # Convert to float32 with image from channel first in [0,255]\n",
    "    # to channel last in [0,1]\n",
    "    state = state.to(torch.float32)\n",
    "    image = image.to(torch.float32) / 255\n",
    "    image = image.permute(2, 0, 1)\n",
    "\n",
    "    # Send data tensors from CPU to GPU\n",
    "    # Should be blocking to avoid race conditions. See:\n",
    "    # https://github.com/huggingface/lerobot/issues/496#issuecomment-2543784955\n",
    "    state = state.to(device, non_blocking=False)\n",
    "    image = image.to(device, non_blocking=False)\n",
    "\n",
    "    # Add extra (empty) batch dimension, required to forward the policy\n",
    "    state = state.unsqueeze(0)\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    # Create the policy input dictionary\n",
    "    observation = {\n",
    "        \"observation.state\": state,\n",
    "        \"observation.image\": image,\n",
    "    }\n",
    "\n",
    "    # Predict the next action with respect to the current observation\n",
    "    with torch.inference_mode():\n",
    "        action = policy.select_action(observation)\n",
    "\n",
    "    # Prepare the action for the environment\n",
    "    numpy_action = action.squeeze(0).to(\"cpu\").numpy()\n",
    "\n",
    "    # Step through the environment and receive a new observation\n",
    "    numpy_observation, reward, terminated, truncated, info = env.step(numpy_action)\n",
    "    print(f\"{step=} {reward=} {terminated=}\")\n",
    "\n",
    "    # Keep track of all the rewards and frames\n",
    "    rewards.append(reward)\n",
    "    frames.append(env.render())\n",
    "\n",
    "    # The rollout is considered done when the success state is reach (i.e. terminated is True),\n",
    "    # or the maximum number of iterations is reached (i.e. truncated is True)\n",
    "    done = terminated | truncated | done\n",
    "    step += 1\n",
    "\n",
    "if terminated:\n",
    "    print(\"Success!\")\n",
    "else:\n",
    "    print(\"Failure!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (680, 680) to (688, 688) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "# Get the speed of environment (i.e. its number of frames per second).\n",
    "fps = env.metadata[\"render_fps\"]\n",
    "\n",
    "# Encode all frames into a mp4 video.\n",
    "video_path = output_directory / \"rollout.mp4\"\n",
    "imageio.mimsave(str(video_path), numpy.stack(frames), fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"outputs/eval/example_pusht_diffusion/rollout.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
